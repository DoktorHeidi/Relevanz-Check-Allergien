{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Vorgehen\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrapen der pdf-Dateien diesmal mit suche im sichtbaren Text der Homepage bei soup.find_all           ########################\n",
    "# f√ºr zwei Ordner: \"pdf_Faelle_und_Tage_nach_Diagnosen_AU\" und \n",
    "#                  \"pdf_Faelle_und_Tage_nach_Diagnosen_KH\"         \n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "#https://www.bundesgesundheitsministerium.de/themen/krankenversicherung/zahlen-und-fakten-zur-krankenversicherung/geschaeftsergebnisse.html#collapse-control-710\n",
    "# Basis-URL der Webseite\n",
    "base_url = \"https://www.bundesgesundheitsministerium.de\"\n",
    "page_url = base_url + \"/themen/krankenversicherung/zahlen-und-fakten-zur-krankenversicherung/geschaeftsergebnisse.html#collapse-control-710\"\n",
    "\n",
    "# Anfrage an die Webseite senden\n",
    "response = requests.get(page_url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Verzeichnis f√ºr PDFs erstellen, Code w√ºrde nichts machen, wenn der Ordner bereits besteht:\n",
    "    # os.makedirs(\"pdf_Faelle _und_Tage_nach_Diagnosen\", exist_ok=True)\n",
    "    # print(\"Es wurde ein Ordner erstellt\")\n",
    "\n",
    "    # zur besseren Nachvollziehbarkeit print-Ausgabe, ob Ordner schon existiert:\n",
    "    ordnername_AU = \"pdf_Faelle_und_Tage_nach_Diagnosen_AU\"\n",
    "\n",
    "    # √úberpr√ºfen, ob der Ordner bereits existiert\n",
    "    if os.path.exists(ordnername_AU):\n",
    "        print(f\"‚ö† Der Ordner '{ordnername_AU}' existiert bereits und wird √ºberschrieben\")\n",
    "        os.makedirs(ordnername_AU, exist_ok=True)\n",
    "\n",
    "    else:\n",
    "        os.makedirs(ordnername_AU)\n",
    "        print(f\"‚úÖ Der Ordner '{ordnername_AU}' wurde neu erstellt.\")\n",
    "\n",
    "    print(\"Ordner AU wurde √ºberpr√ºft\")\n",
    "\n",
    "\n",
    "    ordnername_KH = \"pdf_Faelle_und_Tage_nach_Diagnosen_KH\"\n",
    "\n",
    "    # √úberpr√ºfen, ob der Ordner bereits existiert\n",
    "    if os.path.exists(ordnername_KH):\n",
    "        print(f\"‚ö† Der Ordner '{ordnername_KH}' existiert bereits und wird √ºberschrieben\")\n",
    "        os.makedirs(ordnername_KH, exist_ok=True)\n",
    "\n",
    "    else:\n",
    "        os.makedirs(ordnername_KH)\n",
    "        print(f\"‚úÖ Der Ordner '{ordnername_KH}' wurde neu erstellt.\")\n",
    "\n",
    "    print(\"Ordner KH wurde √ºberpr√ºft\")\n",
    "    \n",
    "    schleife = 0\n",
    "    gefundene_pdf = 1\n",
    "\n",
    "    for ul in soup.find_all(\"ul\", class_=\"c-list c-list--unordered\"):\n",
    "        print(ul)\n",
    "        #href = ul.get('href')\n",
    "            \n",
    "        for a in ul.find_all(\"a\"): #, string=\" und Tage nach Diagnosen\"):\n",
    "            href = a.get('href')\n",
    "            \n",
    "            schleife +=1\n",
    "\n",
    "            #print(f\"1.: Schleife {schleife} wird durchsucht\")   # 1.\n",
    "            #print(\"2.:\", href, \"von Schleife\", schleife)        # 2.\n",
    "            text_schleife = a.get_text()\n",
    "            #print(\"3.:\", text_schleife)                          # 3.      \n",
    "                \n",
    "            print(\"4.: Schleife\", schleife, href)                # 4. \n",
    "\n",
    "\n",
    "            # Suche nach pdf mit richtigem Namen im Link-Text\n",
    "            text_suche = \"und Tage nach Diagnosen\"\n",
    "            if href and href.endswith(\".pdf\") and text_suche in text_schleife:\n",
    "                print(f\"Gefundene PDF: {href}\")\n",
    "\n",
    "\n",
    "                # Sortierung in Ordner f√ºr AU\n",
    "                if gefundene_pdf <= 10:\n",
    "                    \n",
    "                    pdf_url = (f\"{base_url}{href}\") \n",
    "                    print(pdf_url)\n",
    "                    \n",
    "                    pdf_filename = href.split(\"/\")[-1]  # Originaldateiname behalten                \n",
    "                    pdf_pfad = f\"pdf_Faelle_und_Tage_nach_Diagnosen_AU/{gefundene_pdf}_{pdf_filename}\"   #  Eigener Ordner f√ºr AU (ohne KH)                        \n",
    "                    gefundene_pdf +=1\n",
    "                    try:\n",
    "                        pdf_response = requests.get(pdf_url)\n",
    "                        if pdf_response.status_code == 200:\n",
    "                            with open(pdf_pfad, \"wb\") as f:\n",
    "                                f.write(pdf_response.content)\n",
    "                            print(f\"Heruntergeladen: {pdf_pfad}\")\n",
    "                            \n",
    "                        else:\n",
    "                            print(f\"Konnte nicht herunterladen: {pdf_url}\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"Fehler beim Herunterladen {pdf_url}: {e}\")\n",
    "\n",
    "\n",
    "                # Sortierung in Ordner f√ºr KH\n",
    "                elif gefundene_pdf > 10:\n",
    "                    \n",
    "                    pdf_url = (f\"{base_url}{href}\") \n",
    "                    print(pdf_url)\n",
    "                    \n",
    "                    pdf_filename = href.split(\"/\")[-1]  # Originaldateiname behalten                \n",
    "                    pdf_pfad = f\"pdf_Faelle_und_Tage_nach_Diagnosen_KH/{gefundene_pdf}_{pdf_filename}\"   # Eigener Ordner f√ºr Krankenhaus-pdfs                       \n",
    "                    gefundene_pdf +=1\n",
    "                    try:\n",
    "                        pdf_response = requests.get(pdf_url)\n",
    "                        if pdf_response.status_code == 200:\n",
    "                            with open(pdf_pfad, \"wb\") as f:\n",
    "                                f.write(pdf_response.content)\n",
    "                            print(f\"Heruntergeladen: {pdf_pfad}\")\n",
    "                        else:\n",
    "                            print(f\"Konnte nicht herunterladen: {pdf_url}\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"Fehler beim Herunterladen {pdf_url}: {e}\")\n",
    "\n",
    "                \n",
    "\n",
    "            #else:\n",
    "                #   print(\"Fehler beim Abrufen der Webseite.\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Dieser Python-Code verarbeitet mehrere PDF-Dateien aus einem Ordner, extrahiert relevante Daten und speichert diese als CSV-Datei.\n",
    "\n",
    "üîç Schritte im Code\n",
    "Ordner mit PDFs durchsuchen\n",
    "\n",
    "Sammelt alle PDFs im Ordner _______________________________________________________??__pdf_AU_Alter_downloads.\n",
    "\n",
    "Jahr aus Dateinamen extrahieren\n",
    "\n",
    "Sucht eine 4-stellige Jahreszahl im Dateinamen und speichert sie als Spalte.\n",
    "\n",
    "PDF-Text mit pdfplumber extrahieren\n",
    "\n",
    "√ñffnet jede PDF-Datei und liest den gesamten Text pro Seite.\n",
    "\n",
    "Falls eine Seite keinen Text enth√§lt, wird sie √ºbersprungen.\n",
    "\n",
    "Daten filtern & verarbeiten\n",
    "\n",
    "Speichert die erste Zeile jeder Seite als Info.\n",
    "\n",
    "Pr√ºft jede Zeile:\n",
    "\n",
    "Muss mit einem Buchstaben + zwei Zahlen beginnen (ICD-Code).\n",
    "\n",
    "Muss exakt 10 Werte enthalten (Zahlenwerte).\n",
    "\n",
    "F√ºgt das Jahr & Info als zus√§tzliche Spalten hinzu.\n",
    "\n",
    "Daten in pandas.DataFrame speichern\n",
    "\n",
    "Erstellt eine Tabelle mit 12 Spalten.\n",
    "\n",
    "Speichert sie als CSV-Datei im PDF-Ordner.\n",
    "\n",
    "üìÇ Ausgabe\n",
    "Die extrahierten Daten werden als output.csv gespeichert.\n",
    "\n",
    "Sie enthalten die Spalten: \"ICD\", \"Faelle_F\", \"Tage_F\", \"Tage_je_Fall_F\", \"Faelle_M\", \"Tage_M\", \"Tage_je_Fall_M\", \"Faelle_zus\", \"Tage_zus\", \"Tage_je_Fall_zus\", \"Jahr\", \"Info\".\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Umwandlung der Krankenkassendaten AU = Arbeitsunf√§higkeit und speichern in pdf_csv_daten\n",
    "import pdfplumber\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "\n",
    "def extract_year(file_name):\n",
    "    words = re.split(r\"[_\\.\\/]\", file_name)  # Trennt an \"_\" und \".\" gleichzeitig\n",
    "    for word in words:\n",
    "        if word.isdigit() and len(word) == 4:  # Pr√ºfen, ob es genau 4 Ziffern sind\n",
    "            return word  # Jahreszahl gefunden\n",
    "    return \"unbekannt\"  # Keine passende Jahreszahl gefunden\n",
    "\n",
    "# Ordner mit PDFs und csvs:\n",
    "pdf_folder = \"pdf_Faelle_und_Tage_nach_Diagnosen_AU/\"        # AU = Arbeitsunf√§higkeit\n",
    "pdf_folder_dest = \"pdf_csv_daten\"\n",
    "\n",
    "# zur besseren Nachvollziehbarkeit print-Ausgabe, ob Ordner schon existiert:\n",
    "ordnername = pdf_folder_dest\n",
    "\n",
    "# √úberpr√ºfen, ob der Ordner bereits existiert\n",
    "if os.path.exists(ordnername):\n",
    "    print(f\"‚ö† Der Ordner '{ordnername}' existiert bereits und wird √ºberschrieben\")\n",
    "    os.makedirs(ordnername, exist_ok=True)\n",
    "else:\n",
    "    os.makedirs(ordnername)\n",
    "    print(f\"‚úÖ Der Ordner '{ordnername}' wurde neu erstellt.\")\n",
    "\n",
    "print(\"Ordner wurde √ºberpr√ºft\")\n",
    "\n",
    "# Liste aller PDF-Dateien im Ordner erstellen\n",
    "pdf_files = [os.path.join(pdf_folder, f) for f in os.listdir(pdf_folder) if f.endswith(\".pdf\")]\n",
    "\n",
    "# Spaltennamen f√ºr den DataFrame\n",
    "columns = [\"ICD\", \"Faelle_F\", \"Tage_F\", \"Tage_je_Fall_F\",\n",
    "           \"Faelle_M\", \"Tage_M\", \"Tage_je_Fall_M\",\n",
    "           \"Faelle_zus\", \"Tage_zus\", \"Tage_je_Fall_zus\",\n",
    "           \"Jahr\", \"Info\", \"aus_Datei\"]\n",
    "\n",
    "data = []  # Leere Liste f√ºr die extrahierten Daten\n",
    "\n",
    "for pdf_path in pdf_files:\n",
    "    datei_name = os.path.basename(pdf_path)\n",
    "    jahr = extract_year(pdf_path)\n",
    "    T98_found_in_pdf = False  # Flag, um festzustellen, ob T98 bereits gefunden wurde\n",
    "\n",
    "    try:\n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            print(f\"üìÑ Verarbeite Datei: {pdf_path} ({len(pdf.pages)} Seiten)\")\n",
    "            for i, page in enumerate(pdf.pages):\n",
    "                if T98_found_in_pdf:\n",
    "                    # Wenn T98 bereits gefunden wurde, √ºberspringe weitere Seiten\n",
    "                    break\n",
    "\n",
    "                text = page.extract_text()  # extract_text() funktioniert hier super!!!!\n",
    "                if not text:\n",
    "                    continue  # √úberspringt Seiten ohne erkannten Text\n",
    "                lines = text.split(\"\\n\")\n",
    "                info_text = lines[0] if lines else \"\"  # Erste Zeile als \"Info\"\n",
    "\n",
    "                for line in lines:\n",
    "                    if re.match(r\"^T98\", line):\n",
    "                        T98_found_in_pdf = True  # Markieren, dass T98 gefunden wurde\n",
    "                        print(f\"üö® ICD T98 gefunden\")\n",
    "                        values = line.split()  # Trennung nach Leerzeichen\n",
    "                        if len(values) == 10:  # Sicherstellen, dass genau 10 Werte vorliegen\n",
    "                            if jahr == \"unbekannt\":\n",
    "                                jahr = extract_year(info_text)\n",
    "                            values.append(jahr)  # Jahr hinzuf√ºgen\n",
    "                            values.append(info_text)  # Info hinzuf√ºgen\n",
    "                            values.append(datei_name)\n",
    "                            data.append(values)  # alle Werte in die Liste\n",
    "                        break  # Nach T98 in der aktuellen Seite aufh√∂ren\n",
    "                    elif re.match(r\"^[A-Z]\\d{2}\", line):  # Pr√ºft, ob ICD-Code vorhanden ist\n",
    "                        values = line.split()  # Trennung nach Leerzeichen\n",
    "                        if len(values) == 10:  # Sicherstellen, dass genau 10 Werte vorliegen\n",
    "                            if jahr == \"unbekannt\":\n",
    "                                jahr = extract_year(info_text)\n",
    "                            values.append(jahr)  # Jahr hinzuf√ºgen\n",
    "                            values.append(info_text)  # Info hinzuf√ºgen\n",
    "                            values.append(datei_name)\n",
    "                            data.append(values)  # alle Werte in die Liste\n",
    "            # Ende der Seiten-Schleife\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Fehler bei {pdf_path}: {e}\")\n",
    "\n",
    "# DataFrame erstellen und speichern\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "df.to_csv(os.path.join(pdf_folder_dest, \"Krankenkassen_AU.csv\"), index=False, encoding=\"utf-8\", sep=\";\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Umwandlung der Krankenkassendaten (AU mit Krankenhausaufenthalt) und speichern in Ordner \"pdf_csv_daten\"\n",
    "import pdfplumber\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "\n",
    "def extract_year(file_name):\n",
    "    words = re.split(r\"[_\\.\\/]\", file_name)  # Trennt an \"_\" und \".\" gleichzeitig\n",
    "    for word in words:\n",
    "        if word.isdigit() and len(word) == 4:  # Pr√ºfen, ob es genau 4 Ziffern sind\n",
    "            return word  # Jahreszahl gefunden\n",
    "    return \"unbekannt\"  # Keine passende Jahreszahl gefunden\n",
    "\n",
    "# Ordner mit PDFs und csvs:\n",
    "pdf_folder = \"pdf_Faelle_und_Tage_nach_Diagnosen_KH/\"        # AU = Arbeitsunf√§higkeit\n",
    "pdf_folder_dest = \"pdf_csv_daten\"\n",
    "\n",
    "# zur besseren Nachvollziehbarkeit print-Ausgabe, ob Ordner schon existiert:\n",
    "ordnername = pdf_folder_dest\n",
    "\n",
    "# √úberpr√ºfen, ob der Ordner bereits existiert\n",
    "if os.path.exists(ordnername):\n",
    "    print(f\"‚ö† Der Ordner '{ordnername}' existiert bereits und wird √ºberschrieben\")\n",
    "    os.makedirs(ordnername, exist_ok=True)\n",
    "else:\n",
    "    os.makedirs(ordnername)\n",
    "    print(f\"‚úÖ Der Ordner '{ordnername}' wurde neu erstellt.\")\n",
    "\n",
    "print(\"Ordner wurde √ºberpr√ºft\")\n",
    "\n",
    "# Liste aller PDF-Dateien im Ordner erstellen\n",
    "pdf_files = [os.path.join(pdf_folder, f) for f in os.listdir(pdf_folder) if f.endswith(\".pdf\")]\n",
    "\n",
    "# Spaltennamen f√ºr den DataFrame\n",
    "columns = [\"ICD\", \"Faelle_F\", \"Tage_F\", \"Tage_je_Fall_F\",\n",
    "           \"Faelle_M\", \"Tage_M\", \"Tage_je_Fall_M\",\n",
    "           \"Faelle_zus\", \"Tage_zus\", \"Tage_je_Fall_zus\",\n",
    "           \"Jahr\", \"Info\", \"aus_Datei\"]\n",
    "\n",
    "data = []  # Leere Liste f√ºr die extrahierten Daten\n",
    "\n",
    "for pdf_path in pdf_files:\n",
    "    datei_name = os.path.basename(pdf_path)\n",
    "    jahr = extract_year(pdf_path)\n",
    "    T98_found_in_pdf = False  # Flag, um festzustellen, ob T98 bereits gefunden wurde\n",
    "\n",
    "    try:\n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            print(f\"üìÑ Verarbeite Datei: {pdf_path} ({len(pdf.pages)} Seiten)\")\n",
    "            for i, page in enumerate(pdf.pages):\n",
    "                if T98_found_in_pdf:\n",
    "                    # Wenn T98 bereits gefunden wurde, √ºberspringe weitere Seiten\n",
    "                    break\n",
    "\n",
    "                text = page.extract_text()  # extract_text() funktioniert hier super!!!!\n",
    "                if not text:\n",
    "                    continue  # √úberspringt Seiten ohne erkannten Text\n",
    "                lines = text.split(\"\\n\")\n",
    "                info_text = lines[0] if lines else \"\"  # Erste Zeile als \"Info\"\n",
    "\n",
    "                for line in lines:\n",
    "                    if re.match(r\"^T98\", line):\n",
    "                        T98_found_in_pdf = True  # Markieren, dass T98 gefunden wurde\n",
    "                        print(f\"üö® ICD T98 gefunden\")\n",
    "                        values = line.split()  # Trennung nach Leerzeichen\n",
    "                        if len(values) == 10:  # Sicherstellen, dass genau 10 Werte vorliegen\n",
    "                            if jahr == \"unbekannt\":\n",
    "                                jahr = extract_year(info_text)\n",
    "                            values.append(jahr)  # Jahr hinzuf√ºgen\n",
    "                            values.append(info_text)  # Info hinzuf√ºgen\n",
    "                            values.append(datei_name)\n",
    "                            data.append(values)  # alle Werte in die Liste\n",
    "                        break  # Nach T98 in der aktuellen Seite aufh√∂ren\n",
    "                    elif re.match(r\"^[A-Z]\\d{2}\", line):  # Pr√ºft, ob ICD-Code vorhanden ist\n",
    "                        values = line.split()  # Trennung nach Leerzeichen\n",
    "                        if len(values) == 10:  # Sicherstellen, dass genau 10 Werte vorliegen\n",
    "                            if jahr == \"unbekannt\":\n",
    "                                jahr = extract_year(info_text)\n",
    "                            values.append(jahr)  # Jahr hinzuf√ºgen\n",
    "                            values.append(info_text)  # Info hinzuf√ºgen\n",
    "                            values.append(datei_name)\n",
    "                            data.append(values)  # alle Werte in die Liste\n",
    "            # Ende der Seiten-Schleife\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Fehler bei {pdf_path}: {e}\")\n",
    "\n",
    "# DataFrame erstellen und speichern\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "df.to_csv(os.path.join(pdf_folder_dest, \"Krankenkassen_KH.csv\"), index=False, encoding=\"utf-8\", sep=\";\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdf zu 2 csv-Dateien abgeschlossen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erweiterung mit Auswertung der Infos:\n",
    "import pdfplumber\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "\n",
    "# CSV-Datei laden\n",
    "pdf_folder_dest = \"pdf_csv_daten\"\n",
    "csv_file_path = os.path.join(pdf_folder_dest, \"Krankenkassen_KH.csv\")\n",
    "df_KH = pd.read_csv(csv_file_path, sep=\";\")\n",
    "\n",
    "\n",
    "# dataframe df_KH untersuchen\n",
    "df_KH.head()\n",
    "print(df_KH[\"Info\"].unique())\n",
    "print(df_KH.columns)\n",
    "unique_pairs_KH = df_KH[[\"Info\", \"Jahr\"]].drop_duplicates()\n",
    "print(unique_pairs_KH)\n",
    "\n",
    "# in df_KH werden die Rentner nicht ausgenommen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_freiwillig(string):\n",
    "    string = string.lower()\n",
    "    if \"freiwillig\" in string:\n",
    "        return 1    \n",
    "    else:\n",
    "        return 0\n",
    "        \n",
    "\n",
    "df_KH[\"freiwillig\"] = df_KH[\"Info\"].apply(extract_freiwillig)\n",
    "\n",
    "unique_freiwillig_KH = df_KH[[\"freiwillig\", \"Jahr\"]].drop_duplicates()\n",
    "\n",
    "print(unique_freiwillig_KH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV-Datei laden\n",
    "\n",
    "pdf_folder_dest = \"pdf_csv_daten\"\n",
    "csv_file_path = os.path.join(pdf_folder_dest, \"Krankenkassen_AU.csv\")\n",
    "df_AU = pd.read_csv(csv_file_path, sep=\";\")\n",
    "\n",
    "## dataframe df_AU untersuchen\n",
    "df_AU.head()\n",
    "print(df_AU[\"Info\"].unique())\n",
    "\n",
    "unique_pairs_AU = df_AU[[\"Info\", \"Jahr\"]].drop_duplicates()\n",
    "unique_pairs_AU\n",
    "print(unique_pairs_AU)\n",
    "\n",
    "\n",
    "filtered_pairs_AU = unique_pairs_AU[unique_pairs_AU[\"Info\"] == \"Arbeitsunf√§higkeitsf√§lle und -tage der Pflichtmitglieder ohne Rentner (GKV)\"]\n",
    "print(\"\\n filtered 'pflicht ohne Rentner':\\n\",filtered_pairs_AU)\n",
    "\n",
    "filtered_pairs_AU = unique_pairs_AU[unique_pairs_AU[\"Info\"] == \"Arbeitsunf√§higkeitsf√§lle und -tage der Pflichtmitglieder nach Krankheitsarten (absolut)\"]\n",
    "print(\"\\n filtered 'pflicht absolut':\\n\",filtered_pairs_AU)\n",
    "\n",
    "# in den Jahren 2013 und 2015 gab es nur Angaben zu AU der Pflichtversicherten ohne Rentner\n",
    "# in 2014 gab es Angaben sowohl ohne als auch insgesamt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_AU[\"freiwillig\"] = df_AU[\"Info\"].apply(extract_freiwillig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wirklich gut vergleichbar sind von KH aus 2011 bis 2017 (alles pflicht absolut)    -> Label: alle pflicht = 1\n",
    "#                                von AU aus 2013 (alle ohne Rentner)                 -> Label: alle pflicht = 0\n",
    "\n",
    "#                                             , 2016-2020 (alles pflicht absolut)    -> Label: alle pflicht = 1\n",
    "# und                            von AU aus 2014 (hier muss differenziert werden)    -> Label: alle pflicht = 0 oder 1\n",
    "# f√ºr 2012, 2014 und 2015 muss nach Info gelabelt werden. Mit der Info darf der gesamte df_AU bearbeitet werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################\n",
    "# erstmal Label f√ºr KH vergeben:\n",
    "df_KH[\"Krankenhaus\"] = 0\n",
    "df_AU[\"Krankenhaus\"] = 1\n",
    "#################################################################\n",
    "\n",
    "# Label f√ºr Pflicht_alle (wie oben recherchiert)\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "# von KH aus 2011 bis 2017 (alles pflicht absolut)    -> Label: alle pflicht = 1\n",
    "df_KH[\"Pflicht_alle\"] = 1  # hier gab es nur pflichtmitglieder. Rentner wurden nicht ausgenommen\n",
    "\n",
    "# von AU aus 2013 (alle ohne Rentner)                 -> Label: alle pflicht = 0\n",
    "df_AU.loc[df_AU[\"Jahr\"] == 2013, \"Pflicht_alle\"] = 0\n",
    "\n",
    "\n",
    "# von AU aus 2016-2020 (alles pflicht absolut)        -> Label: alle pflicht = 0\n",
    "df_AU.loc[df_AU[\"Jahr\"].between(2016, 2020), \"Pflicht_alle\"] = 1\n",
    "\n",
    "df_AU.loc[df_AU[\"Info\"] == \"Arbeitsunf√§higkeitsf√§lle und -tage der Pflichtmitglieder ohne Rentner (GKV)\", \"Pflicht_alle\"] = 0\n",
    "\n",
    "\n",
    "df_AU.loc[df_AU[\"Info\"] == \"BMG Gesetzliche Krankenversicherung 17.03.2014\", \"Pflicht_alle\"] = 1\n",
    "df_AU.loc[df_AU[\"Info\"] == \"BMG Arbeitsunf√§higkeitsf√§lle und -tage 01.04.2014\", \"Pflicht_alle\"] = 1\n",
    "\n",
    "\n",
    "# loc[] wird verwendet, um nur bestimmte Zeilen zu √§ndern\n",
    "\n",
    "#################################################################\n",
    "# beide df vereinen\n",
    "df_alle = pd.concat([df_AU, df_KH], ignore_index=True)\n",
    "\n",
    "#################################################################\n",
    "# M√§nner und Frauen in Zeilen\n",
    "\n",
    "# Nur relevante Spalten ausw√§hlen (ohne \"zus\"-Spalten)\n",
    "#df = df[[\"ICD\", \"Faelle_F\", \"Tage_F\", \"Tage_je_Fall_F\",\n",
    " #        \"Faelle_M\", \"Tage_M\", \"Tage_je_Fall_M\",\n",
    "  #       \"Pflicht_alle\", \"Krankenhaus\"]]\n",
    "\n",
    "# Daten f√ºr Frauen und M√§nner getrennt speichern und eine neue Spalte \"Geschlecht\" hinzuf√ºgen\n",
    "df_frauen = df_alle[[\"ICD\", \"Faelle_F\", \"Tage_F\", \"Tage_je_Fall_F\", \"Jahr\", \"Krankenhaus\", \"Pflicht_alle\", \"freiwillig\"]].copy()\n",
    "df_frauen[\"male\"] = 0\n",
    "df_frauen.rename(columns={\"Faelle_F\": \"Faelle\", \"Tage_F\": \"Tage\", \"Tage_je_Fall_F\": \"Tage_je_Fall\"}, inplace=True)\n",
    "\n",
    "df_maenner = df_alle[[\"ICD\", \"Faelle_M\", \"Tage_M\", \"Tage_je_Fall_M\", \"Jahr\", \"Krankenhaus\", \"Pflicht_alle\", \"freiwillig\"]].copy()\n",
    "df_maenner[\"male\"] = 1\n",
    "df_maenner.rename(columns={\"Faelle_M\": \"Faelle\", \"Tage_M\": \"Tage\", \"Tage_je_Fall_M\": \"Tage_je_Fall\"}, inplace=True)\n",
    "\n",
    "# Die beiden DataFrames zusammenf√ºgen\n",
    "df_KK_deu = pd.concat([df_frauen, df_maenner], ignore_index=True)   # KK = Krankenkassen\n",
    "\n",
    "\n",
    "# Speichern der aktualisierten Datei\n",
    "pdf_folder_dest = \"pdf_csv_daten\"\n",
    "csv_file_path_erweitert = os.path.join(pdf_folder_dest, \"Krankenkassen_alle.csv\")\n",
    "df_KK_deu.to_csv(csv_file_path_erweitert, index=False, encoding=\"utf-8\", sep=\";\")          # Semikolon ist hier noch wichtig, wegen deutscher Dezimalschreibweise\n",
    "\n",
    "print(f\"‚úÖ Die CSV-Datei wurde erfolgreich erweitert und als {csv_file_path_erweitert} gespeichert!\") \n",
    "\n",
    "###  Hiermit fast fertig zur Analyse, nur die Punkte als Trennzeichen m√ºssen noch entfernt werden und Kommata durch Punkte ausgetauscht werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_KK_deu.head() #### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_KK_deu[[\"Jahr\", \"Pflicht_alle\"]].drop_duplicates())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_KK_deu.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_rows_AU = df_KK_deu[df_KK_deu[\"Pflicht_alle\"].isna()]\n",
    "print(nan_rows_AU)\n",
    "\n",
    "# es gibt keine NaN -> alles prima :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_KK_deu.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in [\"Faelle\", \"Tage\", \"Tage_je_Fall\"]:\n",
    "    # Schritt 1: Tausendertrennzeichen entfernen\n",
    "    df_KK_deu[col] = df_KK_deu[col].astype(str).str.replace(\".\", \"\", regex=False) #regex=False ist hier wichtig, sonst werden die Werte leer\n",
    "\n",
    "\n",
    "\n",
    "# das Entfernen der punkte hat noch nicht geklappt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_KK_deu.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in [\"Faelle\", \"Tage\", \"Tage_je_Fall\"]:\n",
    "\n",
    "    # Schritt 2: Dezimalzeichen umwandeln (Komma ‚Üí Punkt)\n",
    "    df_KK_deu[col] = df_KK_deu[col].str.replace(\",\", \".\", regex=False)\n",
    "\n",
    "    # Schritt 3: Leere Werte in NaN umwandeln, bevor sie als Float gespeichert werden\n",
    "    df_KK_deu[col] = pd.to_numeric(df_KK_deu[col], errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_KK_deu.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_KK_deu.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tabelle in englische Zahlen umgewandelt und jetzt noch als csv gespeichert:\n",
    "\n",
    "pdf_folder_dest = \"pdf_csv_daten\"\n",
    "output_file_path = os.path.join(pdf_folder_dest, \"Krankenkassen_alle_Zahlen_okay.csv\")\n",
    "df_KK_deu.to_csv(output_file_path, index=False, sep=\",\")   # jetzt als Komma, was der default-Einstellung entspricht\n",
    "\n",
    "print(f\"Die umgestaltete Datei wurde erfolgreich als {output_file_path} gespeichert!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# im Folgenden erste Auswertungen\n",
    "# \n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Schritt 1: CSV-Datei laden\n",
    "df = pd.read_csv(r\"pdf_csv_daten\\Krankenkassen_alle_Zahlen_okay.csv\", sep=\",\")   # Benennung ge√§ndert, hier weiter als df aus erstellter csv !!!!!!!!!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# üè∑Ô∏è Nur numerische Spalten ausw√§hlen\n",
    "num_cols = ['Faelle', 'Tage', 'Tage_je_Fall', 'Jahr', 'Krankenhaus',\n",
    "       'Pflicht_alle', 'freiwillig', 'male']\n",
    "df_numeric = df[num_cols]  # DataFrame nur mit Zahlen\n",
    "\n",
    "# üìä Pairplot erstellen\n",
    "sns.pairplot(df_numeric)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä Korrelation berechnen\n",
    "corr_matrix = df_numeric.corr()\n",
    "\n",
    "# üî• Heatmap der Korrelationsmatrix\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
    "plt.title(\"Korrelationsmatrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogramm mit Seaborn\n",
    "# Schritt 1: CSV-Datei laden\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_filtered_1 = df.loc[(df[\"Pflicht_alle\"] == 1) & (df[\"freiwillig\"] == 0)] # & ist wichtig !!! and funktioniert nicht\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.histplot(data=df_filtered_1, x='Jahr', weights='Faelle', hue='male', multiple='dodge', binwidth=1)\n",
    "\n",
    "# Diagramm anpassen\n",
    "plt.xlabel(\"Jahr\")\n",
    "plt.ylabel(\"Anzahl der F√§lle\")\n",
    "plt.title(\"Histogramm der F√§lle nach Jahr und Geschlecht \\n Pflichtversicherte mit Rentnern\")\n",
    "#plt.legend(handles=[\"weiblich\", \"m√§nnlich\"], title=\"Geschlecht\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Erstelle ein Figure-Objekt mit zwei Subplots nebeneinander\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))  # 1 Reihe, 2 Spalten\n",
    "\n",
    "# Erstes Histogramm (Anzahl der F√§lle)\n",
    "sns.histplot(data=df, x=\"Jahr\", weights=\"Faelle\", hue=\"male\", multiple=\"dodge\", binwidth=1, ax=axes[0])\n",
    "axes[0].set_title(\"Histogramm der F√§lle \\n nach Jahr und Geschlecht\")\n",
    "axes[0].set_xlabel(\"Jahr\")\n",
    "axes[0].set_ylabel(\"Anzahl der F√§lle\")\n",
    "axes[0].legend(title=\"male(n/y)\")\n",
    "\n",
    "# Zweites Histogramm (Tage je Fall)\n",
    "sns.histplot(data=df, x=\"Jahr\", weights=\"Tage_je_Fall\", hue=\"male\", multiple=\"dodge\", binwidth=1, ax=axes[1])\n",
    "axes[1].set_title(\"Histogramm der Tage \\n je Fall nach Jahr und Geschlecht\")\n",
    "axes[1].set_xlabel(\"Jahr\")\n",
    "axes[1].set_ylabel(\"Tage je Fall\")\n",
    "axes[1].legend(title=\"male(n/y)\")\n",
    "\n",
    "# Layout anpassen und anzeigen\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "\n",
    "# Interaktiver Scatter-Plot\n",
    "fig = px.scatter(df_filtered_1, x='Jahr', y='Faelle', color='Krankenhaus',\n",
    "                 hover_data={'ICD': True, 'Jahr': True, 'Faelle': True, 'Krankenhaus': True,})\n",
    "\n",
    "# Diagramm anpassen\n",
    "plt.xlabel(\"Jahr\")\n",
    "plt.ylabel(\"Anzahl der F√§lle\")\n",
    "plt.title(\"Histogramm der F√§lle nach Jahr und Einweisung ins Krankenhaus (0/1) \\n Pflichtversicherte mit Rentnern\")\n",
    "#plt.legend(handles=[\"weiblich\", \"m√§nnlich\"], title=\"Geschlecht\")\n",
    "# Diagramm anzeigen\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "\n",
    "# Interaktiver Scatter-Plot\n",
    "fig = px.scatter(df_filtered_1, x='Jahr', y='Faelle', color='Krankenhaus',\n",
    "                 hover_data={'ICD': True, 'Jahr': False, 'Faelle': False, 'Krankenhaus': True,  'male': True})\n",
    "\n",
    "# Diagramm anzeigen\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Neue Spalte f√ºr die ICD-Gruppen nach dem ersten Buchstaben\n",
    "df['ICD_Gruppe'] = df['ICD'].str[0]  # Extrahiert den ersten Buchstaben\n",
    "\n",
    "# Interaktiver Scatter-Plot nach ICD-Gruppen\n",
    "fig = px.scatter(df, x='Jahr', y='Faelle', color='ICD_Gruppe',\n",
    "                 hover_data={'ICD': True, 'Jahr': True, 'Faelle': True, 'Krankenhaus': True, 'Mitglieder': True})\n",
    "\n",
    "# Diagramm anzeigen\n",
    "fig.show()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "\n",
    "# Funktion zur Zuordnung der ICD-Gruppen\n",
    "def kategorisiere_icd(icd_code):\n",
    "    first_letter = icd_code[0]\n",
    "    if first_letter in ['A', 'B']:\n",
    "        return \"Infektionen & Parasiten\"\n",
    "    elif first_letter in ['C', 'D']:\n",
    "        return \"Tumore\"\n",
    "    elif first_letter in ['E']:\n",
    "        return \"Stoffwechsel & Ern√§hrung\"\n",
    "    elif first_letter in ['F']:\n",
    "        return \"Psychische St√∂rungen\"\n",
    "    elif first_letter in ['G']:\n",
    "        return \"Nervensystem\"\n",
    "    elif first_letter in ['H']:\n",
    "        return \"Auge & Ohr\"\n",
    "    elif first_letter in ['I']:\n",
    "        return \"Herz-Kreislauf\"\n",
    "    elif first_letter in ['J']:\n",
    "        return \"Atmungssystem\"\n",
    "    elif first_letter in ['K']:\n",
    "        return \"Verdauungssystem\"\n",
    "    elif first_letter in ['L']:\n",
    "        return \"Haut & Unterhaut\"\n",
    "    elif first_letter in ['M']:\n",
    "        return \"Muskel-Skelett\"\n",
    "    elif first_letter in ['N']:\n",
    "        return \"Urogenitalsystem\"\n",
    "    elif first_letter in ['O']:\n",
    "        return \"Schwangerschaft & Geburt\"\n",
    "    elif first_letter in ['P']:\n",
    "        return \"Perinatale Erkrankungen\"\n",
    "    elif first_letter in ['Q']:\n",
    "        return \"Angeborene Fehlbildungen\"\n",
    "    elif first_letter in ['R']:\n",
    "        return \"Klinische Symptome\"\n",
    "    elif first_letter in ['S', 'T']:\n",
    "        return \"Verletzungen & Vergiftungen\"\n",
    "    elif first_letter in ['U']:\n",
    "        return \"Spezielle Codes\"\n",
    "    elif first_letter in ['V', 'W', 'X', 'Y']:\n",
    "        return \"√Ñu√üere Ursachen\"\n",
    "    elif first_letter in ['Z']:\n",
    "        return \"Gesundheitsfaktoren\"\n",
    "    else:\n",
    "        return \"Unbekannte Kategorie\"\n",
    "\n",
    "# Neue Spalte mit ICD-Kategorien\n",
    "df['ICD_Kategorie'] = df['ICD'].apply(kategorisiere_icd)\n",
    "\n",
    "# Interaktiver Scatter-Plot mit zugeordneten ICD-Kategorien\n",
    "fig = px.scatter(df, x='Jahr', y='Faelle', color='ICD_Kategorie',\n",
    "                 hover_data={'ICD': True, 'Jahr': False, 'Faelle': False, 'Krankenhaus': True, 'Pflicht_alle': False})\n",
    "\n",
    "# Diagramm anzeigen\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "\n",
    "# Einzigartige Werte aus 'Mitglieder' holen\n",
    "mitgliedsgruppen = df['freiwillig'].unique()\n",
    "\n",
    "# Anzahl der Spalten setzen (alle Subplots nebeneinander)\n",
    "fig = make_subplots(rows=1, cols=len(mitgliedsgruppen), shared_xaxes=True, shared_yaxes=True,\n",
    "                    subplot_titles=[f'Mitglieder: {gruppe}' for gruppe in mitgliedsgruppen])\n",
    "\n",
    "# Durch jede Mitgliedergruppe iterieren\n",
    "for i, gruppe in enumerate(mitgliedsgruppen):\n",
    "    subset = df[df['freiwillig'] == gruppe]  # Daten filtern\n",
    "    scatter = go.Scatter(\n",
    "        x=subset['Jahr'],\n",
    "        y=subset['Faelle'],\n",
    "        mode='markers',\n",
    "        marker=dict(size=10, symbol='circle', color=i),\n",
    "        text=subset['ICD'],\n",
    "        hoverinfo='text'\n",
    "    )\n",
    "    fig.add_trace(scatter, row=1, col=i+1)\n",
    "\n",
    "# Layout anpassen\n",
    "fig.update_layout(title=\"Subplots nebeneinander mit ICD-Kategorien\",\n",
    "                  height=600, showlegend=False)\n",
    "\n",
    "# Diagramm anzeigen\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# Liste der Mitgliedsgruppen\n",
    "mitglieder_gruppen = ['Pflichtversicherte ohne Rentner', 'freiwillig Versicherte', 'alle Versicherten']\n",
    "\n",
    "# Subplots erstellen\n",
    "fig = px.scatter(df, x='Jahr', y='Faelle', color='ICD_Kategorie',\n",
    "                 facet_col=\"Mitglieder\",  # Mitgliedergruppen werden nebeneinander dargestellt\n",
    "                 hover_data={'ICD': True, 'Jahr': True, 'Faelle': False, 'Krankenhaus': True, 'Mitglieder': False})\n",
    "\n",
    "# Layout anpassen\n",
    "fig.update_layout(title=\"Scatter-Subplots nach Mitgliedergruppen\")\n",
    "\n",
    "# Diagramm anzeigen\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "#pdf_folder_dest = \n",
    "output_file_path = os.path.join(pdf_folder_dest, \"Krankenkassen_alle_Zahlen_okay_plus-Kategorie.csv\")\n",
    "df.to_csv(output_file_path, index=False, sep=\",\")\n",
    "\n",
    "print(f\"Die umgestaltete Datei wurde erfolgreich als {output_file_path} gespeichert!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
